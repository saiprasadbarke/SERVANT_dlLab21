{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic regression via neural network weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create equations and respective datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create random quadratic equations in the form +/- ax^2 +/- bx +/- c; and generate X, y pairs for the said equations using the following routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_quadratics import RandomQuadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = -5\n",
    "upper_bound = 5\n",
    "round_digits = 3\n",
    "number_of_equations = 10\n",
    "\n",
    "equations = []\n",
    "\n",
    "for _ in range(number_of_equations):\n",
    "    equation = RandomQuadratic(lower_bound=lower_bound, upper_bound=upper_bound, round_digits=round_digits)\n",
    "    equations.append(equation())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'equations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f1a713f13c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float64\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerateDatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdatesets_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_xy_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# dumps makes the float X values in keys into strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'equations' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy.random import uniform\n",
    "from generate_datasets import GenerateDatasets\n",
    "from json import dumps\n",
    "from os import mkdir, path\n",
    "\n",
    "X_values = uniform(-1, 1, 5000).astype(dtype=\"float64\", copy=False)\n",
    "root_dir = \"./datasets\"\n",
    "dataset_generator = GenerateDatasets(equations=equations, X_values=X_values)\n",
    "datesets_dict = dataset_generator.generate_xy_datasets()\n",
    "# dumps makes the float X values in keys into strings\n",
    "\n",
    "print(dumps(datesets_dict, indent=4))\n",
    "GenerateDatasets.write_dataset_to_file(datesets_dict, root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the saved X,y pairs for the respective equations to pytorch dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equations_dataset import EquationsDataset\n",
    "from json import load\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import set_printoptions\n",
    "\n",
    "root_dir = \"./datasets\"\n",
    "equation_data = EquationsDataset(dataset_file_path=f\"{root_dir}/Equation1.json\")\n",
    "#data_loader = DataLoader(equation_data, batch_size=1, shuffle=True)\n",
    "#for idx, xy_values in enumerate(data_loader):\n",
    "    #print(f\"XY at position {idx} is {xy_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680\n",
      "0.6399736243380976\n",
      "2.016488932252981\n",
      "1320\n",
      "-0.6630430210937348\n",
      "7.27321978043593\n"
     ]
    }
   ],
   "source": [
    "#print(data_loader)\n",
    "#print(equation_data.x_values)\n",
    "\n",
    "#train, test = random_split(data_loader, [4000, 1000])\n",
    "\n",
    "#print(vars(train))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#train_loader = DataLoader(train, batch_size=1, shuffle=True)\n",
    "#test_loader = DataLoader(test, batch_size=1, shuffle=True)\n",
    "#print(vars(train_loader))\n",
    "#print(train_loader.X)\n",
    "\n",
    "train_values_x, train_values_y = equation_data.x_values[:4000], equation_data.y_values[:4000] \n",
    "test_values_x, test_values_y = equation_data.x_values[4000:], equation_data.x_values[4000:] \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_values_x, train_values_y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append([X_train[i], y_train[i]])\n",
    "\n",
    "\n",
    "\n",
    "val_data = []\n",
    "for i in range(len(X_val)):\n",
    "    val_data.append([X_val[i], y_val[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "#for idx, xy_values in enumerate(train_loader):\n",
    "    #print(f\"XY at position {idx} is {xy_values}\")\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "#for idx, xy_values in enumerate(val_loader):\n",
    "    #print(f\"XY at position {idx} is {xy_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP to regression on our tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader:DataLoader, validation_dataloader:DataLoader, epochs, model:nn.Module, optimizer, scheduler, criterion):\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    #train-validation loop\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        training_loss = 0.0\n",
    "        #training loop\n",
    "        for _idx , data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.float(), labels.float())\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        train_losses.append(training_loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        #validation loop\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            validation_loss = 0.0\n",
    "            for _idx, data in enumerate(validation_dataloader):\n",
    "                inputs, labels = data\n",
    "                model.eval()\n",
    "                outputs = model(inputs.float())\n",
    "                loss = criterion(outputs.float(), labels.float())\n",
    "                val_losses.append(loss.item())\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "        print(f\"[{epoch+1}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\")\n",
    "        print(f\"\\t Label value: {labels.float().item()}\\t Predicted Output: {outputs.float().item()}\")\n",
    "    #torch.save(model.state_dict(), MODEL_PATH)\n",
    "    return model.state_dict(), train_losses, validation_losses\n",
    "\n",
    "def eval_model(test_dataloader: DataLoader, model: nn.Module, criterion):\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for _idx, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            #print(\"outputs, \", outputs.shape)\n",
    "            #rescaled_outputs = inverse_scaler(outputs, method=\"minmax\")\n",
    "            #print(\"rescaled_outputs: \",rescaled_outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_losses.append(loss.item())\n",
    "        test_loss = np.mean(test_losses)\n",
    "        print(f\"Final test loss: {test_loss:.4f}\")    \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # call constructor from superclass\n",
    "        super(FNN_WO_HPO_3Layer, self).__init__()\n",
    "        # define network layers\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        output = self.fc1(x)\n",
    "        output = self.sigmoid1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.sigmoid2(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN_WO_HPO_3Layer(\n",
      "  (fc1): Linear(in_features=1, out_features=35, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      "  (fc2): Linear(in_features=35, out_features=35, bias=True)\n",
      "  (sigmoid2): Sigmoid()\n",
      "  (fc3): Linear(in_features=35, out_features=1, bias=True)\n",
      ")\n",
      "[1] Training loss: 24.5478\t Validation loss: 21.3039\n",
      "\t Label value: 5.026393413543701\t Predicted Output: 0.48561739921569824\n",
      "[2] Training loss: 19.0194\t Validation loss: 16.5044\n",
      "\t Label value: 2.187842607498169\t Predicted Output: 1.1526610851287842\n",
      "[3] Training loss: 14.8895\t Validation loss: 12.9721\n",
      "\t Label value: 6.9093804359436035\t Predicted Output: 1.798307180404663\n",
      "[4] Training loss: 11.8893\t Validation loss: 10.4810\n",
      "\t Label value: 2.1449997425079346\t Predicted Output: 2.301635503768921\n",
      "[5] Training loss: 9.8673\t Validation loss: 8.8607\n",
      "\t Label value: 4.082357883453369\t Predicted Output: 2.779758930206299\n",
      "[6] Training loss: 8.5345\t Validation loss: 7.8040\n",
      "\t Label value: 9.092066764831543\t Predicted Output: 3.19685697555542\n",
      "[7] Training loss: 7.7139\t Validation loss: 7.1786\n",
      "\t Label value: 2.727735757827759\t Predicted Output: 3.4384925365448\n",
      "[8] Training loss: 7.2329\t Validation loss: 6.8136\n",
      "\t Label value: 1.932289481163025\t Predicted Output: 3.6238813400268555\n",
      "[9] Training loss: 6.9468\t Validation loss: 6.5954\n",
      "\t Label value: 9.490525245666504\t Predicted Output: 3.906968832015991\n",
      "[10] Training loss: 6.7739\t Validation loss: 6.4611\n",
      "\t Label value: 9.879568099975586\t Predicted Output: 4.042850494384766\n",
      "[11] Training loss: 6.6643\t Validation loss: 6.3713\n",
      "\t Label value: 9.027719497680664\t Predicted Output: 4.137436866760254\n",
      "[12] Training loss: 6.5858\t Validation loss: 6.3033\n",
      "\t Label value: 1.9496145248413086\t Predicted Output: 4.033199310302734\n",
      "[13] Training loss: 6.5230\t Validation loss: 6.2463\n",
      "\t Label value: 2.0050597190856934\t Predicted Output: 4.104091167449951\n",
      "[14] Training loss: 6.4662\t Validation loss: 6.1912\n",
      "\t Label value: 3.932460069656372\t Predicted Output: 4.230792999267578\n",
      "[15] Training loss: 6.4093\t Validation loss: 6.1355\n",
      "\t Label value: 3.5786571502685547\t Predicted Output: 4.248442649841309\n",
      "[16] Training loss: 6.3514\t Validation loss: 6.0779\n",
      "\t Label value: 2.177035331726074\t Predicted Output: 4.177341461181641\n",
      "[17] Training loss: 6.2902\t Validation loss: 6.0168\n",
      "\t Label value: 3.6379542350769043\t Predicted Output: 4.283369064331055\n",
      "[18] Training loss: 6.2246\t Validation loss: 5.9510\n",
      "\t Label value: 3.0807459354400635\t Predicted Output: 4.2631072998046875\n",
      "[19] Training loss: 6.1550\t Validation loss: 5.8814\n",
      "\t Label value: 1.9614710807800293\t Predicted Output: 4.116724967956543\n",
      "[20] Training loss: 6.0806\t Validation loss: 5.8066\n",
      "\t Label value: 9.013533592224121\t Predicted Output: 4.484038352966309\n",
      "[21] Training loss: 6.0008\t Validation loss: 5.7270\n",
      "\t Label value: 2.0122461318969727\t Predicted Output: 3.9869167804718018\n",
      "[22] Training loss: 5.9169\t Validation loss: 5.6428\n",
      "\t Label value: 3.4063668251037598\t Predicted Output: 4.305831432342529\n",
      "[23] Training loss: 5.8270\t Validation loss: 5.5526\n",
      "\t Label value: 3.844367265701294\t Predicted Output: 4.344200134277344\n",
      "[24] Training loss: 5.7312\t Validation loss: 5.4567\n",
      "\t Label value: 6.725159168243408\t Predicted Output: 4.513812065124512\n",
      "[25] Training loss: 5.6298\t Validation loss: 5.3551\n",
      "\t Label value: 2.032893657684326\t Predicted Output: 4.0528717041015625\n",
      "[26] Training loss: 5.5224\t Validation loss: 5.2484\n",
      "\t Label value: 4.1934027671813965\t Predicted Output: 4.40274715423584\n",
      "[27] Training loss: 5.4097\t Validation loss: 5.1356\n",
      "\t Label value: 2.180511236190796\t Predicted Output: 4.079493522644043\n",
      "[28] Training loss: 5.2907\t Validation loss: 5.0170\n",
      "\t Label value: 2.371088743209839\t Predicted Output: 3.5633578300476074\n",
      "[29] Training loss: 5.1663\t Validation loss: 4.8933\n",
      "\t Label value: 2.808361291885376\t Predicted Output: 3.3743903636932373\n",
      "[30] Training loss: 5.0361\t Validation loss: 4.7637\n",
      "\t Label value: 8.387378692626953\t Predicted Output: 4.782346725463867\n",
      "[31] Training loss: 4.9001\t Validation loss: 4.6287\n",
      "\t Label value: 2.395569086074829\t Predicted Output: 4.0966572761535645\n",
      "[32] Training loss: 4.7607\t Validation loss: 4.4898\n",
      "\t Label value: 3.2542836666107178\t Predicted Output: 4.336827754974365\n",
      "[33] Training loss: 4.6148\t Validation loss: 4.3461\n",
      "\t Label value: 1.9775596857070923\t Predicted Output: 3.504244804382324\n",
      "[34] Training loss: 4.4660\t Validation loss: 4.1987\n",
      "\t Label value: 6.053058624267578\t Predicted Output: 4.804234981536865\n",
      "[35] Training loss: 4.3122\t Validation loss: 4.0478\n",
      "\t Label value: 4.785555839538574\t Predicted Output: 4.688051700592041\n",
      "[36] Training loss: 4.1578\t Validation loss: 3.8953\n",
      "\t Label value: 3.4340333938598633\t Predicted Output: 4.435543537139893\n",
      "[37] Training loss: 4.0007\t Validation loss: 3.7407\n",
      "\t Label value: 3.3280246257781982\t Predicted Output: 4.412124156951904\n",
      "[38] Training loss: 3.8415\t Validation loss: 3.5851\n",
      "\t Label value: 4.319920539855957\t Predicted Output: 4.697018623352051\n",
      "[39] Training loss: 3.6837\t Validation loss: 3.4316\n",
      "\t Label value: 3.722456216812134\t Predicted Output: 4.57354736328125\n",
      "[40] Training loss: 3.5283\t Validation loss: 3.2808\n",
      "\t Label value: 5.681561470031738\t Predicted Output: 5.047398090362549\n",
      "[41] Training loss: 3.3751\t Validation loss: 3.1328\n",
      "\t Label value: 6.950987339019775\t Predicted Output: 5.311366558074951\n",
      "[42] Training loss: 3.2271\t Validation loss: 2.9907\n",
      "\t Label value: 7.868533611297607\t Predicted Output: 5.495375156402588\n",
      "[43] Training loss: 3.0828\t Validation loss: 2.8531\n",
      "\t Label value: 6.626882553100586\t Predicted Output: 5.404736042022705\n",
      "[44] Training loss: 2.9481\t Validation loss: 2.7243\n",
      "\t Label value: 3.057384490966797\t Predicted Output: 4.378519058227539\n",
      "[45] Training loss: 2.8202\t Validation loss: 2.6027\n",
      "\t Label value: 10.437673568725586\t Predicted Output: 5.99442195892334\n",
      "[46] Training loss: 2.6997\t Validation loss: 2.4884\n",
      "\t Label value: 10.408853530883789\t Predicted Output: 6.082128047943115\n",
      "[47] Training loss: 2.5879\t Validation loss: 2.3831\n",
      "\t Label value: 2.0536270141601562\t Predicted Output: 3.341402292251587\n",
      "[48] Training loss: 2.4843\t Validation loss: 2.2866\n",
      "\t Label value: 7.171976566314697\t Predicted Output: 5.837975025177002\n",
      "[49] Training loss: 2.3892\t Validation loss: 2.1982\n",
      "\t Label value: 2.9133574962615967\t Predicted Output: 4.296896457672119\n",
      "[50] Training loss: 2.3029\t Validation loss: 2.1174\n",
      "\t Label value: 7.233640193939209\t Predicted Output: 5.981109619140625\n",
      "[51] Training loss: 2.2241\t Validation loss: 2.0439\n",
      "\t Label value: 2.64485764503479\t Predicted Output: 4.043417453765869\n",
      "[52] Training loss: 2.1520\t Validation loss: 1.9772\n",
      "\t Label value: 2.390730142593384\t Predicted Output: 1.6024725437164307\n",
      "[53] Training loss: 2.0866\t Validation loss: 1.9163\n",
      "\t Label value: 2.2442636489868164\t Predicted Output: 1.6909078359603882\n",
      "[54] Training loss: 2.0267\t Validation loss: 1.8606\n",
      "\t Label value: 7.674500942230225\t Predicted Output: 6.302584648132324\n",
      "[55] Training loss: 1.9715\t Validation loss: 1.8107\n",
      "\t Label value: 2.022406816482544\t Predicted Output: 2.980250597000122\n",
      "[56] Training loss: 1.9210\t Validation loss: 1.7639\n",
      "\t Label value: 2.0852906703948975\t Predicted Output: 1.7920260429382324\n",
      "[57] Training loss: 1.8741\t Validation loss: 1.7210\n",
      "\t Label value: 3.245467185974121\t Predicted Output: 4.567002773284912\n",
      "[58] Training loss: 1.8310\t Validation loss: 1.6813\n",
      "\t Label value: 1.9298255443572998\t Predicted Output: 2.3356215953826904\n",
      "[59] Training loss: 1.7907\t Validation loss: 1.6433\n",
      "\t Label value: 6.124150276184082\t Predicted Output: 6.108809471130371\n",
      "[60] Training loss: 1.7528\t Validation loss: 1.6091\n",
      "\t Label value: 1.929823637008667\t Predicted Output: 2.280668020248413\n",
      "[61] Training loss: 1.7174\t Validation loss: 1.5764\n",
      "\t Label value: 2.2547521591186523\t Predicted Output: 1.396515965461731\n",
      "[62] Training loss: 1.6839\t Validation loss: 1.5443\n",
      "\t Label value: 8.692752838134766\t Predicted Output: 6.883445739746094\n",
      "[63] Training loss: 1.6519\t Validation loss: 1.5144\n",
      "\t Label value: 2.01462984085083\t Predicted Output: 2.734675884246826\n",
      "[64] Training loss: 1.6214\t Validation loss: 1.4866\n",
      "\t Label value: 2.139558792114258\t Predicted Output: 3.05513858795166\n",
      "[65] Training loss: 1.5924\t Validation loss: 1.4602\n",
      "\t Label value: 2.059309720993042\t Predicted Output: 2.8424901962280273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66] Training loss: 1.5642\t Validation loss: 1.4352\n",
      "\t Label value: 3.304640769958496\t Predicted Output: 4.57495641708374\n",
      "[67] Training loss: 1.5372\t Validation loss: 1.4098\n",
      "\t Label value: 2.7142317295074463\t Predicted Output: 0.9303058981895447\n",
      "[68] Training loss: 1.5113\t Validation loss: 1.3854\n",
      "\t Label value: 3.5728516578674316\t Predicted Output: 4.7899041175842285\n",
      "[69] Training loss: 1.4860\t Validation loss: 1.3623\n",
      "\t Label value: 2.275174379348755\t Predicted Output: 1.2542731761932373\n"
     ]
    }
   ],
   "source": [
    "model = Test_MLP(1, 35, 1)\n",
    "print(model)\n",
    "\n",
    "epochs = 100\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, eta_min=1e-05)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_model(train_loader, val_loader, epochs, model, optimizer, scheduler, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AutoPytorch to search for MLP architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ce071e84c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%pip list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#from autoPyTorch.api.tabular_classification import TabularClassificationTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpbandster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoNetMultilabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoNetRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoNetImageClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoNetImageClassificationMultipleDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_search_space_update\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparameterSearchSpaceUpdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/autonet_classes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_feature_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_feature_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_feature_multilabel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetMultilabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_image_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_image_classification_multiple_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetImageClassificationMultipleDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/autonet_classes/autonet_feature_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautonet_feature_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNetFeatureData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAutoNetClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoNetFeatureData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreset_folder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"feature_classification\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/autonet_classes/autonet_feature_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__license__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"BSD\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAutoNetFeatureData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_encoding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/pipeline/base/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_node\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipelineNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigspace_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/pipeline/base/pipeline_node.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mConfigSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoPyTorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_option\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigOption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ConfigSpace/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mConfigSpace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_space\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mConfigurationSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mConfigSpace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalHyperparameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mConfigSpace/configuration_space.pyx\u001b[0m in \u001b[0;36minit ConfigSpace.configuration_space\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mConfigSpace/hyperparameters.pyx\u001b[0m in \u001b[0;36minit ConfigSpace.hyperparameters\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "#%pip list\n",
    "#from autoPyTorch.api.tabular_classification import TabularClassificationTask\n",
    "from autoPyTorch import AutoNetRegression\n",
    "from autoPyTorch.data_management.data_manager import DataManager\n",
    "\n",
    "\n",
    "# Note: You can write your own datamanager! Call fit train, valid data (numpy matrices) \n",
    "#dm = DataManager()\n",
    "#dm.generate_regression(num_features=21, num_samples=1500)\n",
    "\n",
    "# Note: every parameter has a default value, you do not have to specify anything. The given parameter allow a fast test.\n",
    "#autonet = AutoNetRegression(budget_type='epochs', min_budget=1, max_budget=9, num_iterations=1, log_level='info')\n",
    "\n",
    "#res = autonet.fit(X_train=X_train, Y_train=y_train, X_valid=X_val, Y_valid=y_val)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
