{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create equations to mlp datasets from trained networks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create quadratic equations in the form +/- ax^2 +/- bx +/- c as our targets to the input values as our network weights."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def parse_equation_json(dataset_file_path):\r\n",
    "    with open(dataset_file_path) as json_file:\r\n",
    "        data = load(json_file)\r\n",
    "        #print(data)\r\n",
    "        x_values = list(data.keys())\r\n",
    "        y_values = list(data.values())\r\n",
    "        assert len(x_values) == len(y_values)\r\n",
    "    return x_values, y_values\r\n",
    "\r\n",
    "\r\n",
    "create_dataset()\r\n",
    "x_values, y_values = parse_equation_json(f\"{root_dir}/equations_to_mlp_weights.json\")\r\n",
    "\r\n",
    "train_values_x, train_values_y = x_values[:4000], y_values[:4000] \r\n",
    "test_values_x, test_values_y = x_values[4000:], x_values[4000:] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import torch\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_values_x, train_values_y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "train_data = []\r\n",
    "for i in range(len(X_train)):\r\n",
    "    train_data.append([X_train[i], torch.FloatTensor(y_train[i])])\r\n",
    "\r\n",
    "val_data = []\r\n",
    "for i in range(len(X_val)):\r\n",
    "    val_data.append([X_val[i], torch.FloatTensor(y_val[i])])\r\n",
    "\r\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\r\n",
    "\r\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP to Decoder Architecture in our implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We process the network weights through a MLP and then use the learned representation as input to our decoder model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['-1.2*x*x+1.3*x-1',\n",
       " tensor([-5.6723e-01, -4.2020e-01,  1.3257e+00,  7.5389e-01,  8.2234e-02,\n",
       "         -5.8438e-01, -9.7138e-01,  4.4880e-01,  2.2155e-01, -3.1306e-01,\n",
       "         -9.2360e-04, -3.4064e-01, -1.6338e-02, -3.2545e-01, -4.2002e-03,\n",
       "         -1.5795e-01, -2.0448e-02, -3.3488e-01,  3.3168e-01, -2.7872e-02,\n",
       "          3.0185e-01,  2.3806e-02, -2.9166e-01, -2.7286e-01, -1.5448e-02,\n",
       "         -3.4943e-02, -3.2462e-01,  6.1753e-01,  3.4095e-02, -1.2253e-01,\n",
       "         -6.8272e-02,  5.5982e-01,  4.1066e-03,  1.9089e-01, -2.6787e-01,\n",
       "         -3.3988e-01, -2.7152e-01, -9.2338e-02, -1.2238e-01,  3.3914e-01,\n",
       "          4.4633e-01,  2.8089e-01,  3.9832e-02, -2.3664e-01, -1.4197e-01,\n",
       "          7.1590e-01,  5.9507e-01, -2.1987e-01, -2.0779e-01, -5.6828e-02,\n",
       "          3.5495e-01,  3.3513e-01, -1.5567e-02,  2.0529e-01, -2.1851e-01,\n",
       "          3.1577e-01, -2.2781e-01,  1.4184e-01,  1.7817e-01, -1.5977e-03,\n",
       "         -1.5645e-01,  3.2901e-01, -3.1186e-01, -1.8062e-01,  2.5690e-01,\n",
       "          2.6784e-01,  3.4066e-04, -2.6388e-01, -7.4937e-02,  4.8506e-01,\n",
       "         -3.4449e-01,  2.8903e-01,  1.3590e-01, -9.6284e-01,  1.9424e-01,\n",
       "          3.9267e-01,  2.6846e-01, -3.4295e-01,  2.2045e-01, -3.4180e-01,\n",
       "         -1.0540e-01,  3.5724e-01,  3.3793e-01, -7.6242e-02, -1.0873e-01,\n",
       "         -9.0291e-02, -5.2506e-02, -7.5562e-01, -2.3689e-01,  6.1185e-01,\n",
       "          5.7800e-01,  1.4463e-01, -1.6436e-01,  2.0202e-01, -2.5926e-01,\n",
       "          5.3227e-02,  5.2052e-01,  4.7812e-01,  1.8136e-01,  3.2200e-02,\n",
       "          3.4549e-01,  6.6308e-02, -5.7287e-02,  4.2611e-02, -3.4906e-01,\n",
       "         -3.0178e-01,  1.4023e-01,  3.3140e-01, -7.0118e-01,  3.4249e-01,\n",
       "          7.7099e-03,  5.4792e-01,  1.6240e-01, -1.5584e-01, -1.3803e-01,\n",
       "         -3.2965e-01,  2.6548e-01, -1.4260e-01, -1.3434e-01,  2.5253e-01,\n",
       "         -4.5947e-01, -6.9091e-01, -4.3746e-01, -7.2003e-01, -3.8686e-01,\n",
       "          1.4622e-01, -5.9689e-01,  2.1381e-01])]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "class Encoder_MLP(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, input_size, hidden_size, output_size):\r\n",
    "        # call constructor from superclass\r\n",
    "        super(Encoder_MLP, self).__init__()\r\n",
    "        # define network layers\r\n",
    "        self.input_size = input_size\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\r\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size*2)\r\n",
    "        self.fc4 = nn.Linear(hidden_size*2, output_size)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.layerNorm = nn.LayerNorm(input_size)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        # define forward pass\r\n",
    "        output = self.fc1(x)\r\n",
    "        output = self.relu(output)\r\n",
    "        #output = self.layerNorm(output)\r\n",
    "        output = self.fc2(output)\r\n",
    "        #output = self.layerNorm(output)\r\n",
    "        output = self.relu(output)\r\n",
    "        output = self.fc3(output)\r\n",
    "        #output = self.layerNorm(output)\r\n",
    "        output = self.relu(output)\r\n",
    "        output = self.fc4(output)\r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "def train_model(train_dataloader:DataLoader, validation_dataloader:DataLoader, epochs, model:nn.Module, optimizer, scheduler, criterion):\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    #train-validation loop\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        training_loss = 0.0\n",
    "        #training loop\n",
    "        for _idx , data in enumerate(train_dataloader):\n",
    "            equation, mlp_weights = data\n",
    "            print(equation)\n",
    "            print(mlp_weights)\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            outputs = model(mlp_weights.float())\n",
    "            print(outputs)\n",
    "            print(outputs.shape)\n",
    "            loss = criterion(outputs.float(), labels.float())\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        train_losses.append(training_loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        #validation loop\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            validation_loss = 0.0\n",
    "            for _idx, data in enumerate(validation_dataloader):\n",
    "                inputs, labels = data\n",
    "                model.eval()\n",
    "                outputs = model(inputs.float())\n",
    "                loss = criterion(outputs.float(), labels.float())\n",
    "                val_losses.append(loss.item())\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "        print(f\"[{epoch+1}] Training loss: {training_loss:.7f}\\t Validation loss: {validation_loss:.7f}\")\n",
    "        print(f\"\\t Label value: {labels.float().item()}\\t Predicted Output: {outputs.float().item()}\")\n",
    "    #torch.save(model.state_dict(), MODEL_PATH)\n",
    "    return model.state_dict()\n",
    "\n",
    "def eval_model(test_dataloader: DataLoader, model: nn.Module, criterion):\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for _idx, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            #print(\"outputs, \", outputs.shape)\n",
    "            #rescaled_outputs = inverse_scaler(outputs, method=\"minmax\")\n",
    "            #print(\"rescaled_outputs: \",rescaled_outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_losses.append(loss.item())\n",
    "        test_loss = np.mean(test_losses)\n",
    "        print(f\"Final test loss: {test_loss:.4f}\")    \n",
    "    return test_losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "model = Encoder_MLP(128, 256, 512)\n",
    "print(model)\n",
    "\n",
    "epochs = 1\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, eta_min=1e-05)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "mf_dict =train_model(train_loader, val_loader, epochs, model, optimizer, scheduler, criterion)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoder_MLP(\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (layerNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "('+0.4*x*x-3*x-4',)\n",
      "tensor([[ 0.4607, -0.6348, -1.1444, -0.2364,  1.0517, -0.4547,  0.7143, -0.8074,\n",
      "          0.5914,  0.0328, -0.3927,  0.4257,  0.6577,  0.3466,  0.4597, -0.0125,\n",
      "          0.0529, -0.0317,  0.0373, -0.1681, -0.0171, -0.1467, -0.1179,  0.3150,\n",
      "          0.6529,  0.2568, -0.2176, -0.0025,  0.2332,  0.0062,  0.7766, -0.2544,\n",
      "         -0.1316, -0.3324,  0.3309,  0.4621, -0.3207,  0.3432,  0.0976, -0.0318,\n",
      "         -0.3379,  0.1935, -0.0147,  0.2849, -0.3320,  0.1327,  0.1421, -0.2154,\n",
      "         -0.1293, -0.3491,  0.2319, -0.2571, -0.2726, -0.2270, -0.2554, -0.0509,\n",
      "         -0.1492,  0.2148,  0.6068,  0.3771,  0.0486,  0.5961, -0.0996,  0.2171,\n",
      "          0.5676,  0.1947,  0.6848, -0.5296, -0.0785,  0.0594, -0.3984, -0.1601,\n",
      "         -0.0087,  0.2211, -0.0365, -0.0280, -0.1444,  0.0133,  0.0211, -0.0071,\n",
      "         -0.0383,  0.1516,  0.0340, -0.1100,  0.3498, -0.3238, -0.1973,  0.1388,\n",
      "         -0.3708,  0.1451,  0.2645,  0.0191, -0.0758, -0.0639, -0.3842, -0.0199,\n",
      "         -0.0345,  0.1674, -0.3128,  0.0887,  0.0060, -0.3235,  0.3925, -0.3360,\n",
      "         -0.3553,  0.2448,  0.7091,  0.2018,  0.3960, -0.3807, -0.1012, -0.2764,\n",
      "         -0.3915,  0.5822,  0.2048,  0.0993,  0.1366, -0.0162, -0.2778, -0.1415,\n",
      "         -0.7113,  0.2173,  0.2395,  0.2062,  0.0638,  0.4729, -0.5691, -0.5639]])\n",
      "tensor([[-0.0126,  0.0151, -0.0315,  0.0632,  0.0591, -0.0024, -0.0062,  0.0210,\n",
      "         -0.0593, -0.0265, -0.0056,  0.0474, -0.0136, -0.0510, -0.0013,  0.0480,\n",
      "          0.0102, -0.0145, -0.0441, -0.0017, -0.0274,  0.0165, -0.0228, -0.0097,\n",
      "          0.0118,  0.0289, -0.0754, -0.0255,  0.0119,  0.0267, -0.0030,  0.0540,\n",
      "         -0.0101,  0.0417,  0.0309,  0.0014,  0.0314, -0.0195, -0.0162,  0.0012,\n",
      "         -0.0220,  0.0129, -0.0189, -0.0479,  0.0503,  0.0232, -0.0760, -0.0370,\n",
      "          0.0426, -0.0348,  0.0054,  0.0594,  0.0493,  0.0408,  0.0349, -0.0536,\n",
      "          0.0310,  0.0569,  0.0229, -0.0205,  0.0438,  0.0121,  0.0459, -0.0249,\n",
      "         -0.0086, -0.0358,  0.0362, -0.0374,  0.0064,  0.0217,  0.0114, -0.0116,\n",
      "          0.0559, -0.0480, -0.0071,  0.0288, -0.0257, -0.0183,  0.0535,  0.0078,\n",
      "          0.0238, -0.0005, -0.0215, -0.0245, -0.0325, -0.0427,  0.0299, -0.0133,\n",
      "         -0.0019,  0.0428, -0.0162,  0.0297, -0.0347,  0.0035,  0.0536,  0.0139,\n",
      "          0.0092,  0.0550,  0.0056, -0.0265,  0.0118,  0.0639, -0.0161,  0.0268,\n",
      "         -0.0315, -0.0274,  0.0464, -0.0172, -0.0147,  0.0487,  0.0057, -0.0439,\n",
      "          0.0271, -0.0136,  0.0433,  0.0428,  0.0179,  0.0532,  0.0505,  0.0196,\n",
      "         -0.0171, -0.0512,  0.0383, -0.0413,  0.0872,  0.0190, -0.0253, -0.0161,\n",
      "         -0.0451,  0.0135, -0.0637,  0.0590,  0.0237, -0.0196,  0.0532,  0.0356,\n",
      "          0.0285, -0.0254, -0.0083,  0.0144, -0.0125, -0.0482,  0.0081,  0.0016,\n",
      "         -0.0446,  0.0109, -0.0286, -0.0082,  0.0018,  0.0038, -0.0323, -0.0018,\n",
      "         -0.0188,  0.0173,  0.0348, -0.0215,  0.0235, -0.0266,  0.0043,  0.0111,\n",
      "          0.0057,  0.0046,  0.0290,  0.0242, -0.0127,  0.0418, -0.0225,  0.0236,\n",
      "          0.0232, -0.0147, -0.0392,  0.0213, -0.0088,  0.0030,  0.0184, -0.0118,\n",
      "         -0.0103,  0.0448,  0.0167, -0.0444,  0.0564, -0.0356, -0.0365,  0.0270,\n",
      "          0.0351, -0.0235, -0.0105,  0.0386, -0.0555, -0.0024,  0.0486,  0.0021,\n",
      "          0.0350,  0.0068, -0.0091,  0.0573, -0.0204, -0.0398, -0.0546, -0.0292,\n",
      "          0.0293, -0.0070,  0.0323,  0.0066,  0.0131, -0.0255, -0.0214, -0.0455,\n",
      "          0.0437,  0.0139, -0.0123, -0.0759, -0.0172, -0.0284,  0.0484,  0.0075,\n",
      "          0.0399, -0.0082, -0.0227, -0.0491,  0.0041,  0.0373, -0.0043, -0.0295,\n",
      "         -0.0189,  0.0122,  0.0160, -0.0104, -0.0334, -0.0336, -0.0209, -0.0304,\n",
      "         -0.0514, -0.0015, -0.0188, -0.0583, -0.0198,  0.0544, -0.0097, -0.0108,\n",
      "          0.0302,  0.0333,  0.0328,  0.0566, -0.0321,  0.0562,  0.0323, -0.0349,\n",
      "          0.0251,  0.0696, -0.0644, -0.0316, -0.0528,  0.0300, -0.0363, -0.0503,\n",
      "         -0.0535, -0.0176, -0.0081,  0.0041, -0.0877,  0.0283, -0.0126, -0.0402,\n",
      "          0.0079, -0.0437,  0.0099,  0.0059,  0.0800, -0.0077,  0.0109,  0.0289,\n",
      "          0.0215,  0.0098,  0.0299, -0.0260, -0.0323, -0.0312, -0.0120, -0.0268,\n",
      "         -0.0250, -0.0462, -0.0043, -0.0290,  0.0159,  0.0390,  0.0220,  0.0382,\n",
      "         -0.0518, -0.0441,  0.0121, -0.0456, -0.0271, -0.0506,  0.0053, -0.0215,\n",
      "         -0.0606, -0.0255,  0.0051,  0.0069,  0.0477, -0.0124,  0.0047, -0.0020,\n",
      "         -0.0403, -0.0648,  0.0078,  0.0323, -0.0017, -0.0068,  0.0409, -0.0673,\n",
      "         -0.0243, -0.0477,  0.0480,  0.0194, -0.0266,  0.0396, -0.0154,  0.0299,\n",
      "          0.0039,  0.0474,  0.0292, -0.0335, -0.0320,  0.0237, -0.0444,  0.0298,\n",
      "         -0.0036, -0.0368,  0.0046, -0.0041, -0.0072,  0.0453,  0.0328,  0.0294,\n",
      "          0.0288,  0.0351,  0.0223, -0.0104,  0.0544, -0.0319, -0.0318, -0.0161,\n",
      "          0.0225,  0.0363,  0.0396, -0.0308, -0.0095,  0.0180, -0.0492, -0.0108,\n",
      "          0.0509, -0.0436,  0.0023, -0.0482, -0.0137,  0.0610,  0.0428, -0.0386,\n",
      "          0.0375, -0.0026, -0.0105,  0.0296, -0.0080, -0.0168,  0.0350,  0.0227,\n",
      "          0.0322, -0.0224,  0.0870, -0.0046,  0.0555, -0.0383,  0.0122, -0.0219,\n",
      "          0.0039, -0.0156, -0.0306,  0.0555,  0.0186,  0.0090,  0.0035, -0.0291,\n",
      "         -0.0049, -0.0278,  0.0107,  0.0330,  0.0307,  0.0079,  0.0499, -0.0105,\n",
      "         -0.0551,  0.0610,  0.0325, -0.0255,  0.0547, -0.0096,  0.0237, -0.0107,\n",
      "         -0.0274,  0.0044,  0.0634, -0.0088,  0.0428,  0.0438,  0.0567, -0.0445,\n",
      "          0.0141,  0.0020,  0.0477,  0.0186, -0.0287, -0.0358, -0.0305, -0.0333,\n",
      "          0.0338,  0.0303, -0.0347,  0.0515,  0.0288,  0.0224, -0.0171, -0.0331,\n",
      "          0.0487, -0.0108, -0.0151,  0.0580,  0.0173,  0.0090,  0.0435,  0.0478,\n",
      "         -0.0175,  0.0395, -0.0776, -0.0093, -0.0031, -0.0027, -0.0159, -0.0640,\n",
      "          0.0049,  0.0083,  0.0154,  0.0027,  0.0137,  0.0370, -0.0144, -0.0542,\n",
      "          0.0037,  0.0478, -0.0157,  0.0329, -0.0324, -0.0207, -0.0389, -0.0152,\n",
      "          0.0174, -0.0054,  0.0209, -0.0287, -0.0168,  0.0168,  0.0146, -0.0274,\n",
      "         -0.0101, -0.0132,  0.0389, -0.0225,  0.0330, -0.0111,  0.0239, -0.0258,\n",
      "         -0.0017, -0.0150,  0.0574, -0.0191,  0.0031, -0.0101,  0.0335,  0.0131,\n",
      "          0.0276, -0.0418,  0.0230,  0.0465, -0.0187,  0.0563,  0.0547, -0.0107,\n",
      "         -0.0185, -0.0572,  0.0037, -0.0672, -0.0226,  0.0509,  0.0245, -0.0423,\n",
      "         -0.0556, -0.0095, -0.0304, -0.0109,  0.0683, -0.0125, -0.0292,  0.0052,\n",
      "         -0.0061, -0.0075,  0.0272,  0.0089,  0.0004,  0.0030,  0.0037, -0.0050]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'labels' referenced before assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f40aa3ee4be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmf_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-5145555ec4f0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataloader, validation_dataloader, epochs, model, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'labels' referenced before assignment"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}